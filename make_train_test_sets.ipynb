{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce CSVs for Train, Test, and Val sets\n",
    "\n",
    "Use these CSVs with the CropMaker script to produce training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GSVutils.utils\n",
    "from GSVutils.utils import GSV_IMAGE_WIDTH, GSV_IMAGE_HEIGHT\n",
    "from GSVutils.point import Point\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db_export = '../minus_onboard.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We'll start by loading all features into objects associated with their parent panos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feat(object):\n",
    "    def __init__(self, row):\n",
    "        self.pano_id = row[0]\n",
    "        self.sv_image_x = float(row[1])\n",
    "        self.sv_image_y = float(row[2])\n",
    "        self.label_type = int(row[3])\n",
    "        self.photographer_heading = float(row[4]) if row[4] is not None else None\n",
    "        self.heading = float(row[5]) if row[5] is not None else None\n",
    "        self.label_id = int(row[7])  if row[7] is not None else None\n",
    "        \n",
    "    def to_row(self):\n",
    "        row =[]\n",
    "        row.append(self.pano_id)\n",
    "        row.append(self.sv_image_x)\n",
    "        row.append(self.sv_image_y)\n",
    "        row.append(self.label_type)\n",
    "        row.append(self.photographer_heading)\n",
    "        row.append(self.heading)\n",
    "        row.append(self.label_id)\n",
    "        return row\n",
    "    \n",
    "    def point(self):\n",
    "        return Point( self.sv_image_x, self.sv_image_y )\n",
    "    \n",
    "    def __str__(self):\n",
    "        label = GSVutils.utils.label_from_int[self.label_type-1]\n",
    "        return '{} at {}'.format(label, self.point() )\n",
    "    \n",
    "    @classmethod\n",
    "    def header_row(cls):\n",
    "        row = ['Pano ID','SV_x','SV_y','Label',\n",
    "               'Photographer Heading','Heading','Label ID']\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pano(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feats = {1:[], 2:[], 3:[], 4:[]}\n",
    "        self.pano_id        = None\n",
    "        self.photog_heading = None\n",
    "\n",
    "    def add_feature(self, row):\n",
    "        feat = Feat(row)\n",
    "        if self.pano_id is None:\n",
    "            self.pano_id = feat.pano_id\n",
    "        assert self.pano_id == feat.pano_id\n",
    "        \n",
    "        if self.photog_heading is None:\n",
    "            self.photog_heading = feat.photographer_heading\n",
    "        \n",
    "        self.feats[feat.label_type].append( feat )\n",
    "            \n",
    "    def __hash__(self):\n",
    "        return hash( self.pano_id )\n",
    "    \n",
    "    def all_feats(self):\n",
    "        ''' iterate over all features, regardless of type '''\n",
    "        for label, features in self.feats.iteritems():\n",
    "            for feature in features:\n",
    "                yield feature\n",
    "    \n",
    "    def __str__(self):\n",
    "        s = 'pano{}\\n'.format(self.pano_id)\n",
    "        for feat in self.all_feats():\n",
    "            s += '{}\\n'.format(feat)\n",
    "        return s\n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' return the total number of feats in this pano '''\n",
    "        c = 0\n",
    "        for _ in self.all_feats():\n",
    "            c += 1\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from 58034 panos\n",
      "Curb Cut            149227\n",
      "Missing Cut         19543\n",
      "Obstruction         22016\n",
      "Sfc Problem         8780\n"
     ]
    }
   ],
   "source": [
    "counts = defaultdict(int)\n",
    "panos = defaultdict( Pano )\n",
    "\n",
    "with open(path_to_db_export) as dbfile:\n",
    "    reader = csv.reader(dbfile)\n",
    "    \n",
    "    for row in reader:\n",
    "        pano_id = row[0]\n",
    "        sv_image_x = float(row[1])\n",
    "        sv_image_y = float(row[2])\n",
    "        label_type = int(row[3])\n",
    "        photographer_heading = float(row[4])\n",
    "        heading = float(row[5])\n",
    "        label_id = int(row[7])\n",
    "        \n",
    "        if len( pano_id ) < 2:\n",
    "            continue\n",
    "        \n",
    "        if label_type in (1,2,3,4):\n",
    "            # extract only ramp, missing ramps,\n",
    "            # sfc probs, and obstructions\n",
    "            panos[pano_id].add_feature( row )\n",
    "            \n",
    "            counts[label_type] += 1\n",
    "\n",
    "print \"Loaded features from {} panos\".format( len(panos) )\n",
    "for feature, count in counts.iteritems():\n",
    "    name = GSVutils.utils.label_from_int[feature-1]\n",
    "    print \"{:<20}{}\".format(name, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign sets using a 80/10/10 Train/Test/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = defaultdict(set)\n",
    "\n",
    "for pano_id in panos:\n",
    "    r = random.random()\n",
    "    if r <.8:\n",
    "        assign = 'Train'\n",
    "    elif r < .9:\n",
    "        assign = 'Test'\n",
    "    else:\n",
    "        assign = 'Val'\n",
    "    \n",
    "    datasets[assign].add(panos[pano_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at how the numbers break down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Train   Test    Val     Total   \n",
      "Num Panos         46463   5797    5774    58034   \n",
      "Missing Cut       15692   1872    1979    19543   \n",
      "Sfc Problem       7003    897     880     8780    \n",
      "Obstruction       17519   2305    2192    22016   \n",
      "Curb Cut          119799  14731   14697   149227  \n",
      "Total Features    160013  19805   19748   199566  \n"
     ]
    }
   ],
   "source": [
    "counts = defaultdict( lambda: defaultdict(int) )\n",
    "\n",
    "for name, panos in datasets.iteritems():\n",
    "    counts[name]['Num Panos'] = len(panos)\n",
    "    \n",
    "    for pano in panos:\n",
    "        for label, feats in pano.feats.iteritems():\n",
    "            label_t = GSVutils.utils.label_from_int[label-1]\n",
    "            counts[name][label_t]   += len(feats)\n",
    "            counts[name]['Total Features'] += len(feats)\n",
    "\n",
    "s = '{:<18}' + 4 * '{:<8}'\n",
    "print s.format(\"\", 'Train', 'Test', 'Val', 'Total')\n",
    "for name in counts['Train']:\n",
    "    row = [name]\n",
    "    for dataset in ('Train', 'Test', 'Val'):\n",
    "        row.append( counts[dataset][name] )\n",
    "    row.append( sum(row[1:]) )\n",
    "    print s.format(*row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we'll sliding window over the panos\n",
    "\n",
    "and assign labels to them based on proximity to true features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(pano, stride=100, bottom_space=1600, side_space=300, cor_thresh=70):\n",
    "    ''' take in a pano and produce a set of feats, ready for writing to a file\n",
    "        labels assigned if the crop is within cor_thresh of a true label\n",
    "        \n",
    "        try cor_thresh = stride/sqrt(2)\n",
    "    '''\n",
    "    x, y = side_space, 0\n",
    "    while(y > - (GSV_IMAGE_HEIGHT/2 - bottom_space)):\n",
    "        while(x < GSV_IMAGE_WIDTH - side_space):\n",
    "            # do things in one row\n",
    "            \n",
    "            # check if there's any features near this x,y point\n",
    "            p = Point(x,y)\n",
    "            \n",
    "            label = 8 # for null\n",
    "            for feat in pano.all_feats():\n",
    "                if p.dist( feat.point() ) <= cor_thresh:\n",
    "                    if label == 8:\n",
    "                        label = feat.label_type\n",
    "                    else:\n",
    "                        if label != feat.label_type:\n",
    "                            #print \"Found conflicting labels, skipping.\"\n",
    "                            continue\n",
    "            row = [pano.pano_id, x, y, label, pano.photog_heading, None,None,None]\n",
    "            yield Feat(row)\n",
    "            \n",
    "            x += stride\n",
    "        y -= stride # jump down a row\n",
    "        x = side_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We've got far too many nullcrops, now.\n",
    "\n",
    "Let's throw out a bunch so we only have a few per pano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cull_dataset_and_export_to_csv(dataset, file_to_write, nulls_per_pano=3):\n",
    "    print \"Computing sliding window for {} panos\".format( len(dataset) )\n",
    "    feats = defaultdict(set)\n",
    "    \n",
    "    panocount = 0 \n",
    "    for pano in dataset:\n",
    "        nulls = []\n",
    "        for feat in sliding_window(pano):\n",
    "            if feat.label_type != 8: feats[feat.label_type].add( feat )\n",
    "            elif feat.label_type == 8:\n",
    "                nulls.append(feat)\n",
    "        nulls_to_keep = random.sample(nulls, nulls_per_pano)\n",
    "        for feat in nulls_to_keep:\n",
    "            feats[feat.label_type].add( feat )\n",
    "        panocount += 1\n",
    "                    \n",
    "    print  '{:<18}{}'.format('Feature Type', 'Count')\n",
    "    \n",
    "    with open(file_to_write, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow( Feat.header_row() )\n",
    "        for label, fs in feats.iteritems():\n",
    "            label_t = GSVutils.utils.label_from_int[label-1] if label != 8 else 'Nullcrop'\n",
    "            c = 0\n",
    "            for feat in fs:\n",
    "                writer.writerow( feat.to_row() )\n",
    "                c += 1\n",
    "            print '{:<18}{}'.format(label_t, c)\n",
    "    print \"Wrote features from {} panos to {}\".format(panocount, file_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Test set\n",
      "Computing sliding window for 5797 panos\n",
      "Feature Type      Count\n",
      "Nullcrop          17391\n",
      "Curb Cut          19451\n",
      "Missing Cut       2616\n",
      "Obstruction       3314\n",
      "Sfc Problem       1288\n",
      "Wrote features from 5797 panos to dataset_csvs/Test.csv\n",
      "Processing Train set\n",
      "Computing sliding window for 46463 panos\n",
      "Feature Type      Count\n",
      "Nullcrop          139389\n",
      "Curb Cut          159039\n",
      "Missing Cut       21552\n",
      "Obstruction       25162\n",
      "Sfc Problem       9933\n",
      "Wrote features from 46463 panos to dataset_csvs/Train.csv\n",
      "Processing Val set\n",
      "Computing sliding window for 5774 panos\n",
      "Feature Type      Count\n",
      "Nullcrop          17322\n",
      "Curb Cut          19538\n",
      "Missing Cut       2685\n",
      "Obstruction       3153\n",
      "Sfc Problem       1205\n",
      "Wrote features from 5774 panos to dataset_csvs/Val.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, dataset in datasets.iteritems():\n",
    "    print 'Processing {} set'.format(name)\n",
    "    cull_dataset_and_export_to_csv(dataset, 'dataset_csvs/{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can use set_cropper.py to write these to a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
