{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification from scratch with TPUs on Cloud ML Engine using ResNet\n",
    "\n",
    "This notebook demonstrates how to do image classification from scratch on a flowers dataset using TPUs and the resnet trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'sidewalk-dl' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'sidewalk_crops_subset' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JPEG images to TensorFlow Records\n",
    "\n",
    "My dataset consists of JPEG images in Google Cloud Storage. I have two CSV files that are formatted as follows:\n",
    "   image-name, category\n",
    "\n",
    "Instead of reading the images from JPEG each time, we'll convert the JPEG data and store it as TF Records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sidewalk_crops_subset/imgs/10.jpg,curb_ramp\r\n",
      "gs://sidewalk_crops_subset/imgs/100.jpg,curb_ramp\r\n",
      "gs://sidewalk_crops_subset/imgs/10000.jpg,curb_ramp\r\n",
      "gs://sidewalk_crops_subset/imgs/100000.jpg,curb_ramp\r\n",
      "gs://sidewalk_crops_subset/imgs/100001.jpg,curb_ramp\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cat gs://sidewalk_crops_subset/train_set.csv | head -5 > /tmp/input.csv\n",
    "cat /tmp/input.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curb_ramp\r\n",
      "missing_ramp\r\n",
      "no_sidewalk\r\n",
      "obstruction\r\n",
      "occlusion\r\n",
      "other\r\n",
      "surface_problem\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cat gs://sidewalk_crops_subset/train_set.csv  | sed 's/,/ /g' | awk '{print $2}' | sort | uniq > /tmp/labels.txt\n",
    "cat /tmp/labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the TPU repo\n",
    "\n",
    "Let's git clone the repo and get the preprocessing and model files. The model code has imports of the form:\n",
    "<pre>\n",
    "import resnet_model as model_lib\n",
    "</pre>\n",
    "We will need to change this to:\n",
    "<pre>\n",
    "from . import resnet_model as model_lib\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting copy_resnet_files.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile copy_resnet_files.sh\n",
    "#!/bin/bash\n",
    "rm -rf tpu\n",
    "git clone https://github.com/tensorflow/tpu\n",
    "cd tpu\n",
    "TFVERSION=$1\n",
    "echo \"Switching to version r$TFVERSION\"\n",
    "git checkout r$TFVERSION\n",
    "cd ..\n",
    "  \n",
    "MODELCODE=tpu/models/official/resnet\n",
    "OUTDIR=mymodel\n",
    "rm -rf $OUTDIR\n",
    "\n",
    "# preprocessing\n",
    "cp -r imgclass $OUTDIR   # brings in setup.py and __init__.py\n",
    "cp tpu/tools/datasets/jpeg_to_tf_record.py $OUTDIR/trainer/preprocess.py\n",
    "\n",
    "# model: fix imports\n",
    "for FILE in $(ls -p $MODELCODE | grep -v /); do\n",
    "    CMD=\"cat $MODELCODE/$FILE \"\n",
    "    for f2 in $(ls -p $MODELCODE | grep -v /); do\n",
    "        MODULE=`echo $f2 | sed 's/.py//g'`\n",
    "        CMD=\"$CMD | sed 's/^import ${MODULE}/from . import ${MODULE}/g' \"\n",
    "    done\n",
    "    CMD=\"$CMD > $OUTDIR/trainer/$FILE\"\n",
    "    eval $CMD\n",
    "done\n",
    "find $OUTDIR\n",
    "echo \"Finished copying files into $OUTDIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tpu'...\n",
      "remote: Enumerating objects: 1, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 2355 (delta 0), reused 0 (delta 0), pack-reused 2354\u001b[K\n",
      "Receiving objects: 100% (2355/2355), 1.38 MiB | 14.75 MiB/s, done.\n",
      "Resolving deltas: 100% (1436/1436), done.\n",
      "Switching to version r1.9\n",
      "Branch 'r1.9' set up to track remote branch 'r1.9' from 'origin'.\n",
      "Switched to a new branch 'r1.9'\n",
      "mymodel\n",
      "mymodel/setup.py\n",
      "mymodel/trainer\n",
      "mymodel/trainer/.gitignore\n",
      "mymodel/trainer/imagenet_input.py\n",
      "mymodel/trainer/preprocess.py\n",
      "mymodel/trainer/README.md\n",
      "mymodel/trainer/resnet_k8s.yaml\n",
      "mymodel/trainer/resnet_main.py\n",
      "mymodel/trainer/resnet_model.py\n",
      "mymodel/trainer/resnet_preprocessing.py\n",
      "mymodel/trainer/__init__.py\n",
      "Finished copying files into mymodel\n"
     ]
    }
   ],
   "source": [
    "!bash ./copy_resnet_files.sh $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU service account\n",
    "\n",
    "Allow Cloud ML Engine to access the TPU and bill to your project\n",
    "\n",
    "690616814548-compute@developer.gserviceaccount.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting enable_tpu_mlengine.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile enable_tpu_mlengine.sh\n",
    "SVC_ACCOUNT=$(curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\"  \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT}:getConfig \\\n",
    "              | grep tpuServiceAccount | tr '\"' ' ' | awk '{print $3}' )\n",
    "echo \"Enabling TPU service account $SVC_ACCOUNT to act as Cloud ML Service Agent for project $PROJECT\"\n",
    "gcloud projects add-iam-policy-binding $PROJECT \\\n",
    "    --member serviceAccount:$SVC_ACCOUNT --role roles/ml.serviceAgent\n",
    "echo \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting enable_tpu_mlengine.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile enable_tpu_mlengine.sh\n",
    "SVC_ACCOUNT=690616814548-compute@developer.gserviceaccount.com\n",
    "echo \"Enabling TPU service account $SVC_ACCOUNT to act as Cloud ML Service Agent for project $PROJECT\"\n",
    "gcloud projects add-iam-policy-binding $PROJECT \\\n",
    "    --member serviceAccount:$SVC_ACCOUNT --role roles/ml.serviceAgent\n",
    "echo \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   235    0   235    0     0    594      0 --:--:-- --:--:-- --:--:--   593\n",
      "Enabling TPU service account service-149546808362@cloud-tpu.iam.gserviceaccount.com to act as Cloud ML Service Agent for project sidewalk-dl\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-690616814548@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-690616814548@container-engine-robot.iam.gserviceaccount.com\n",
      "  role: roles/container.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-690616814548@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:690616814548-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:690616814548@cloudservices.gserviceaccount.com\n",
      "  - serviceAccount:service-690616814548@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:690616814548-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:service-149546808362@cloud-tpu.iam.gserviceaccount.com\n",
      "  - serviceAccount:service-690616814548@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/ml.serviceAgent\n",
      "- members:\n",
      "  - user:galenorama@gmail.com\n",
      "  - user:jang.esther@gmail.com\n",
      "  role: roles/owner\n",
      "etag: BwV7wJNNP3s=\n",
      "version: 1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!bash ./enable_tpu_mlengine.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run it over full training and evaluation datasets.  This will happen in Cloud Dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache-beam==2.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/81/ea/11cec69a659af024f7f37e928ff533ad5e30b7a519d9982e2bb5b81fcb52/apache-beam-2.8.0.zip\n",
      "  Saved /tmp/tmpAmj08Q/apache-beam-2.8.0.zip\n",
      "Successfully downloaded apache-beam\n",
      "Collecting apache-beam==2.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/63/ea5453ba656d060936acf41d2ec057f23aafd69649e2129ac66fdda67d48/apache_beam-2.8.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "  Saved /tmp/tmpAmj08Q/apache_beam-2.8.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Successfully downloaded apache-beam\n",
      "Read in 5 labels, from curb_ramp to nullcrop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "CommandException: 1 files/objects could not be removed.\n",
      "WARNING:tensorflow:From /mnt/c/Users/gweld/sidewalk/training-data-analyst/quests/tpu/mymodel/trainer/preprocess.py:215: __init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "/home/gweld/anaconda2/envs/sidewalk_gcloud/lib/python2.7/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:795: DeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  standard_options = transform_node.inputs[0].pipeline.options.view_as(\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mymodel\n",
    "gsutil -m rm -rf gs://${BUCKET}/tpu/resnet/data\n",
    "python -m trainer.preprocess \\\n",
    "       --train_csv gs://sidewalk_crops_subset/train_set.csv \\\n",
    "       --validation_csv gs://sidewalk_crops_subset/eval_set.csv \\\n",
    "       --labels_file gs://sidewalk_crops_subset/labels.txt \\\n",
    "       --project_id $PROJECT \\\n",
    "       --output_dir gs://${BUCKET}/tpu/resnet/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above preprocessing step will take <b>15-20 minutes</b>. Wait for the job to finish before you proceed. Navigate to [Cloud Dataflow section of GCP web console](https://console.cloud.google.com/dataflow) to monitor job progress. You will see something like this <img src=\"dataflow.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, you can simply copy my already preprocessed files and proceed to the next step:\n",
    "<pre>\n",
    "gsutil -m cp gs://cloud-training-demos/tpu/resnet/data/* gs://${BUCKET}/tpu/resnet/copied_data\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00000-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00001-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00002-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00003-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00004-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00005-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00006-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00007-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00008-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00009-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00010-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00011-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00012-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00013-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00014-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00015-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00016-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00017-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00018-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00019-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00020-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00021-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00022-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00023-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00024-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00025-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00026-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00027-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00028-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00029-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00030-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00031-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00032-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00033-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00034-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00035-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00036-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00037-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00038-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00039-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00040-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00041-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00042-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00043-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00044-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00045-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00046-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00047-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00048-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00049-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00050-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00051-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00052-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00053-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00054-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00055-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00056-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00057-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00058-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00059-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00060-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00061-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00062-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00063-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00064-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00065-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00066-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00067-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00068-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00069-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00070-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00071-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00072-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00073-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00074-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00075-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00076-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00077-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00078-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00079-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00080-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00081-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00082-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00083-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00084-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00085-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/train-00086-of-00087\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00000-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00001-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00002-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00003-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00004-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00005-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00006-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00007-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00008-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00009-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00010-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00011-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00012-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00013-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00014-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00015-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00016-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00017-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00018-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00019-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00020-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00021-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/validation-00022-of-00023\n",
      "gs://sidewalk_crops_subset/tpu/resnet/data/tmp/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/tpu/resnet/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on the Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--num_train_images=223912  --num_eval_images=24430  --num_label_classes=4"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo -n \"--num_train_images=$(gsutil cat gs://sidewalk_crops_subset/train_set.csv | wc -l)  \"\n",
    "echo -n \"--num_eval_images=$(gsutil cat gs://sidewalk_crops_subset/eval_set.csv | wc -l)  \"\n",
    "echo -n \"--num_label_classes=$(gsutil cat gs://sidewalk_crops_subset/labels.txt | wc -l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sidewalk_crops_subset/tpu/resnet/trained us-central1 imgclass_181206_194319\n",
      "jobId: imgclass_181206_194319\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [imgclass_181206_194319] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe imgclass_181206_194319\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs imgclass_181206_194319\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TOPDIR=gs://${BUCKET}/tpu/resnet\n",
    "OUTDIR=${TOPDIR}/trained\n",
    "JOBNAME=imgclass_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR  # Comment out this line to continue training from the last time\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --python-version=2.7 \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.resnet_main \\\n",
    "  --package-path=$(pwd)/mymodel/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=BASIC_TPU \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  --data_dir=${TOPDIR}/data \\\n",
    "  --model_dir=${OUTDIR} \\\n",
    "  --resnet_depth=18 \\\n",
    "  --train_batch_size=128 --eval_batch_size=32 --skip_host_call=True \\\n",
    "  --steps_per_eval=250 --train_steps=1000 \\\n",
    "  --num_train_images=223912  --num_eval_images=24430  --num_label_classes=5 \\\n",
    "  --export_dir=${OUTDIR}/export\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above training job will take 15-20 minutes. \n",
    "Wait for the job to finish before you proceed. \n",
    "Navigate to [Cloud ML Engine section of GCP web console](https://console.cloud.google.com/mlengine) \n",
    "to monitor job progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sidewalk_crops_subset/tpu/resnet/trained/export/\n",
      "gs://sidewalk_crops_subset/tpu/resnet/trained/export/1543473192/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the training charts with TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named datalab.ml",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-b21a6ea67561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTDIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://{}/tpu/resnet/trained/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUCKET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named datalab.ml"
     ]
    }
   ],
   "source": [
    "OUTDIR = 'gs://{}/tpu/resnet/trained/'.format(BUCKET)\n",
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped Tensorboard\n"
     ]
    }
   ],
   "source": [
    "TensorBoard().stop(11531)\n",
    "print(\"Stopped Tensorboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were the charts I got (I set smoothing to be zero):\n",
    "<img src=\"resnet_traineval.png\" height=\"50\"/>\n",
    "As you can see, the final blue dot (eval) is quite close to the lowest training loss, indicating that the model hasn't overfit.  The top_1 accuracy on the evaluation dataset, however, is 80% which isn't that great. More data would help.\n",
    "<img src=\"resnet_accuracy.png\" height=\"50\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"sidewalk\"\n",
    "MODEL_VERSION=resnet\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/ | tail -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting/deploying sidewalk resnet from gs://sidewalk_crops_subset/tpu/resnet/trained/export/1543964310/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting version [resnet]......\n",
      ".....................................done.\n",
      "This will delete model [sidewalk]...\n",
      "\n",
      "Do you want to continue (Y/n)?  Please enter 'y' or 'n':  Please enter 'y' or 'n':  \n",
      "Deleting model [sidewalk]...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"sidewalk\"\n",
    "MODEL_VERSION=resnet\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/ | tail -1)\n",
    "echo \"Deleting/deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "\n",
    "# comment/uncomment the appropriate line to run. The first time around, you will need only the two create calls\n",
    "# But during development, you might need to replace a version by deleting the version and creating it again\n",
    "\n",
    "gcloud ml-engine versions delete --quiet ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use saved_model_cli to find out what inputs the model expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['image_bytes'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: Placeholder:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['classes'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: ArgMax:0\n",
      "  outputs['probabilities'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 5)\n",
      "      name: softmax_tensor:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "saved_model_cli show --dir $(gsutil ls gs://${BUCKET}/tpu/resnet/trained/export/ | tail -1) --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model expects image_bytes.  This is typically base64 encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images that is available on Google Cloud Storage <img src=\"http://storage.googleapis.com/cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg\" /> and convert it to a base64-encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, sys, json\n",
    "import tensorflow as tf\n",
    "with tf.gfile.FastGFile('gs://sidewalk_crops_subset/imgs/10.jpg', 'r') as ifp:\n",
    "  with open('test.json', 'w') as ofp:\n",
    "    image_data = ifp.read()\n",
    "    img = base64.b64encode(image_data)\n",
    "    json.dump({\"image_bytes\": {\"b64\": img}}, ofp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 gweld gweld 295832 Dec  6 11:36 test.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSES  PROBABILITIES\n",
      "0        [0.43101173639297485, 0.17029161751270294, 0.014127411879599094, 0.005831782706081867, 0.37766680121421814, 0.0005188215873204172, 0.0005518007092177868]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model=sidewalk --version=nullcrop --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does CLASS no. 3 correspond to? (remember that classes is 0-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunflowers\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "head -4 /tmp/labels.txt | tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you would invoke those predictions without using gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response={u'predictions': [{u'probabilities': [0.0012481402372941375, 0.0010495249880477786, 7.82029837864684e-06, 0.9976732134819031, 2.1333773474907503e-05], u'classes': 3}]}\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import base64, sys, json\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.gfile.FastGFile('gs://cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg', 'r') as ifp:\n",
    "  credentials = GoogleCredentials.get_application_default()\n",
    "  api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "  \n",
    "  request_data = {'instances':\n",
    "  [\n",
    "      {\"image_bytes\": {\"b64\": base64.b64encode(ifp.read())}}\n",
    "  ]}\n",
    "\n",
    "  parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'flowers', 'resnet')\n",
    "  response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "  print \"response={0}\".format(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2018 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
