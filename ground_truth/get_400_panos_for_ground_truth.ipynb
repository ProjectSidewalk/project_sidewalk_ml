{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination\n",
    "\n",
    "Here we're gonna randomly sample 100 of each feature type from the val set, then add in extras to get to 400 panos total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repo_path = '/Users/galenweld/project_sidewalk_ml'\n",
    "repo_path = '/mnt/c/Users/gweld/sidewalk/sidewalk_ml'\n",
    "#path_to_labels    = os.path.join(repo_path, 'visualizations/minus_onboard.csv')\n",
    "path_to_labels    = os.path.join(repo_path, '../minus_onboard.csv')\n",
    "path_to_train_set = os.path.join(repo_path, 'dataset_csvs/Train.csv')\n",
    "path_to_val_set   = os.path.join(repo_path, 'dataset_csvs/Val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pano ID SV_x SV_y Label Photographer Heading Heading Label ID\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_train_set) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "print \" \".join(header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_panos = set()\n",
    "\n",
    "with open(path_to_train_set) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        pano_id = row[0]\n",
    "        train_panos.add(pano_id)\n",
    "train_panos.remove(\"Pano ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_panos = set()\n",
    "\n",
    "with open(path_to_val_set) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        pano_id = row[0]\n",
    "        val_panos.add(pano_id)\n",
    "val_panos.remove(\"Pano ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46463, 5774)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_panos), len(val_panos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Num Panos\n",
      "  1   4075\n",
      "  2   1106\n",
      "  3   1417\n",
      "  4   685\n"
     ]
    }
   ],
   "source": [
    "panos_by_label = defaultdict(set)\n",
    "\n",
    "with open(path_to_labels) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        pano_id = row[0]\n",
    "        label = int(row[3])\n",
    "        if label in (1,2,3,4) and pano_id in val_panos:\n",
    "            panos_by_label[label].add(pano_id)\n",
    "\n",
    "print \"{:^6}{}\".format(\"Label\", \"Num Panos\")\n",
    "for label, panos in panos_by_label.items():\n",
    "    print \"{:^6}{}\".format(label, len(panos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Num Panos\n",
      "  1   100\n",
      "  2   100\n",
      "  3   100\n",
      "  4   100\n"
     ]
    }
   ],
   "source": [
    "sampled_panos = {}\n",
    "\n",
    "for label, panos in panos_by_label.items():\n",
    "    s = set()\n",
    "    while len(s) < 100:\n",
    "        num_needed = 100- len(s)\n",
    "        s |= set( random.sample(panos, num_needed) )\n",
    "    sampled_panos[label] = s\n",
    "\n",
    "print \"{:^6}{}\".format(\"Label\", \"Num Panos\")\n",
    "for label, panos in sampled_panos.items():\n",
    "    print \"{:^6}{}\".format(label, len(panos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    }
   ],
   "source": [
    "all_samples = set()\n",
    "for s in sampled_panos.values():\n",
    "    all_samples |= s\n",
    "print len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "while len(all_samples) < 400:\n",
    "    all_samples |= set( random.sample(panos_by_label[1],1) )\n",
    "print len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampled_panos_for_ground_truth.txt', 'w') as f:\n",
    "    for pano_id in all_samples:\n",
    "        f.writelines(pano_id+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going back to get panos with most Missing Curb Ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_panos_missing_ramps = defaultdict(int)\n",
    "\n",
    "with open(path_to_labels) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        pano_id = row[0]\n",
    "        label = int(row[3])\n",
    "        if label == 2 and pano_id in val_panos:\n",
    "            val_panos_missing_ramps[pano_id] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17Kf6DFklN_pCy36L5OOUw 18\n",
      "bjkfY9Oa3jV3B-g8o2p4Uw 18\n",
      "WSkAfEpA_OtK5u4T57ykTQ 16\n",
      "arbGR9mQ_Gbr-LNWio3iKw 13\n",
      "2Lzx4aEfsCmiX1dlyr7DNQ 10\n",
      "v1L4iS6mB7ZndEroZRyHww 10\n",
      "ZQdiE5shETg2os-kciAHqA 10\n",
      "Ju-5ZGopQtmIcvwhciFbIw 7\n",
      "M_ob8iOynti4Vy8XQmnClg 7\n",
      "U1EwgzvToBS4kXB_hTV8WQ 7\n",
      "TNUrQtVnmTG99hJuSwDYHg 6\n",
      "l5eYxTKkeNVRZjg6NkuHpQ 6\n",
      "oWiYpE-qlIm4xv7ZtjPh9Q 6\n",
      "kSh8CSVzsV2q3IAWBpSjoA 6\n",
      "xQ7UxceNjMkmfUbawDHkyA 6\n",
      "stw2DE74Z6T7UiVFg7Vt-Q 6\n",
      "IWSfloST5O5Cc3OpV1xqag 6\n",
      "yGVUb9aH5ENvW5ZfMy4a8Q 6\n",
      "GXruCkxCjHAWUDqcmHfAxw 6\n",
      "rSfND_SnSBwCuUubAOduxQ 6\n"
     ]
    }
   ],
   "source": [
    "for pid, count in sorted(val_panos_missing_ramps.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print pid, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 402 already sampled panos.\n"
     ]
    }
   ],
   "source": [
    "already_sampled = set()\n",
    "with open('sampled_panos_for_ground_truth.txt') as f:\n",
    "    for line in f:\n",
    "        already_sampled.add(line[:-1])\n",
    "        \n",
    "print \"Counted {} already sampled panos.\".format(len(already_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping already sampled pano\n",
      "bjkfY9Oa3jV3B-g8o2p4Uw 18\n",
      "WSkAfEpA_OtK5u4T57ykTQ 16\n",
      "arbGR9mQ_Gbr-LNWio3iKw 13\n",
      "2Lzx4aEfsCmiX1dlyr7DNQ 10\n",
      "v1L4iS6mB7ZndEroZRyHww 10\n",
      "ZQdiE5shETg2os-kciAHqA 10\n",
      "Ju-5ZGopQtmIcvwhciFbIw 7\n",
      "M_ob8iOynti4Vy8XQmnClg 7\n",
      "U1EwgzvToBS4kXB_hTV8WQ 7\n",
      "TNUrQtVnmTG99hJuSwDYHg 6\n",
      "l5eYxTKkeNVRZjg6NkuHpQ 6\n",
      "oWiYpE-qlIm4xv7ZtjPh9Q 6\n",
      "kSh8CSVzsV2q3IAWBpSjoA 6\n",
      "xQ7UxceNjMkmfUbawDHkyA 6\n",
      "skipping already sampled pano\n",
      "IWSfloST5O5Cc3OpV1xqag 6\n",
      "yGVUb9aH5ENvW5ZfMy4a8Q 6\n",
      "GXruCkxCjHAWUDqcmHfAxw 6\n",
      "rSfND_SnSBwCuUubAOduxQ 6\n",
      "C2ArtRTlgvVJswjb_egxeQ 6\n",
      "7Nm83eNWhDpo1Au27Qw1qA 6\n",
      "1-2MNgRG-iN6DwktcIRE_g 6\n",
      "skipping already sampled pano\n",
      "R7oO4MPA6YpZ1DmLo2PVlg 6\n",
      "2qo8E-Wboo329orUetqzAQ 6\n",
      "uYR2NZpjnSuHRo9WXozX7g 6\n",
      "_ksfAI3JAieAsCq4uGGUYw 6\n",
      "2u2OFTh_9QFMVM2umyJ-cQ 5\n",
      "BX-IlV8IsOsA2RGm7YhRFQ 5\n",
      "skipping already sampled pano\n",
      "da6e7v5cS5EfUQiUmpkCSg 5\n",
      "kEe57krKXVdJSB_epVDnMA 5\n",
      "3fNxkHJU1uA0qRWD91QGJw 5\n",
      "skipping already sampled pano\n",
      "skipping already sampled pano\n",
      "03nLDyiGmStaf5UsEY9TMQ 5\n",
      "j72ac6giHtyulFl-xH6I5g 5\n",
      "zKlyR-dpvLhFqqMeW4bI0A 5\n",
      "JvZt17AeNDxQCGK4mVr10A 5\n",
      "z4c_pAaqVvJj_SqgiuFK3A 5\n",
      "aKUFAcYMIoFi-vLuphkXEg 5\n",
      "EuE9l3upJLYZc0TkNgpeLQ 5\n",
      "RvngA272SGgBz_-qwAIHGw 5\n",
      "Hz_orhHGW4owMuaI5m5h6A 5\n",
      "vmSXasyMy1SIhB2Hu0CsEA 5\n",
      "msX_xRxqbQzqI7stVZGdaw 5\n",
      "AsDH8oipghVD_V70d3eryQ 4\n",
      "W37l4nMS8wVrjMuMYK7tPA 4\n",
      "WrjRFedE1vlJeHv4OYP_MQ 4\n",
      "KSzvUsP7b5OhimasvyQzbw 4\n",
      "wsw0DjfRWo4Gc9qTBnf65A 4\n",
      "OhT9AkA_t6Am6IT81h11iA 4\n",
      "re1DBg-VJh_zWTpF46DXiA 4\n",
      "MDKuTaaOV1KtfSeqtABUfA 4\n",
      "TwK74VdIatWaDsg67bA54w 4\n",
      "skipping already sampled pano\n",
      "xuauO4ap0tIKJ8K7X9b2qw 4\n",
      "skipping already sampled pano\n",
      "lZlc7Fmgw9dFHYZGYEu05w 4\n",
      "w6rcVPGTl3-B9bKdriCDMw 4\n",
      "mVBKkmgguSjDnbs1rSg5eg 4\n",
      "XNUdc2mm7ozwMAk-j4Mndw 4\n",
      "gFPeHAt6wb8eSte427IutQ 4\n",
      "grFvKdyH7tKP16Q2gbWg2A 4\n",
      "T6uA_hY3yjP0f6y9hqGSHA 4\n",
      "4771YFmFGjOsfbO2JNF3Xw 4\n",
      "qDGzFosKWkBX-ARg6gPDAA 4\n",
      "dCjtVStuIKocwZAoO2L8PQ 4\n",
      "OUAPdrMcjdVHNqxk_sASSg 4\n",
      "XYiwotxBGt7_TgBQw3Cdyg 4\n",
      "skipping already sampled pano\n",
      "ZTT7WXHrMfB1ZbwlLt6oaA 4\n",
      "skipping already sampled pano\n",
      "5CQ0WnQwvnh9HPXiS-_KLQ 4\n",
      "dq3-S0podC2EHMPmGP4BQw 4\n",
      "Tg0UYfCBxL1ZGZZ1prTtqA 4\n",
      "NZbHpPUpu7njzto4pGJ-Zg 4\n",
      "ZF57WmU4GQL0kwTtkimpfA 4\n",
      "uqjOFYdp7um4-2zadNOK9Q 4\n",
      "3GMNNXy_PxS1i9Usdae61Q 4\n",
      "wEwbutAdprRvYkYXG9ghNw 4\n",
      "ADGKUYWbu5fu24N8GV2YFQ 4\n",
      "l_9FPIASRsPfYemsdiW-RA 4\n",
      "skipping already sampled pano\n",
      "8_1KLpjlMX1eg_YWCTV3Sw 4\n",
      "hKYcnso8Kco3m39cFH9KyQ 4\n",
      "1a1UlhadSS_3dNtc5oI10Q 4\n",
      "WkDVxno4uAjilVcWZFFnLQ 4\n",
      "zEUMl1ncJjfYP49H3CqE1Q 4\n",
      "aIlQs2Fwwh3-SKX07bcVHw 4\n",
      "skipping already sampled pano\n",
      "j9bVvvz-hJYTEqvqpbQ9Xg 4\n",
      "ggi31w4l0Vi3pQJ90mysrA 4\n",
      "w0N_jOmbNWdM8U2tRg4U1Q 4\n",
      "skipping already sampled pano\n",
      "qS6YhjS_NAgpcs-4bugJow 4\n",
      "q9cZRfYV8pku_0lHGXawEQ 4\n",
      "skipping already sampled pano\n",
      "8ITsTqV25DW4n0GzUXGsvQ 4\n"
     ]
    }
   ],
   "source": [
    "with open('new_panos_with_missing_ramps.txt', 'w') as f:\n",
    "    for pid, count in sorted(val_panos_missing_ramps.items(), key=lambda x: x[1], reverse=True)[:100]:\n",
    "        if pid in already_sampled:\n",
    "            print \"skipping already sampled pano\"\n",
    "            continue\n",
    "        print pid, count\n",
    "        f.writelines(pid+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
